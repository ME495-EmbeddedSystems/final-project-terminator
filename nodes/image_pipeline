#!/usr/bin/env python
"""
DESCRIPTION:
+ Takes in data from cameras and distributes it to the external package nodes that process it.
+ Recieves the processed data from the external nodes and publishes it to the nodes implementing the moving of Baxter.


SUBSCRIBERS:
+ leftCamera (/cameras/left_hand_camera/image) - Wrist camera's image
  type = sensor_msgs/Image

+ calibrationMatrixLeftSub (/cameras/left_hand_camera/camera_info) - Camera's calibration matrix
  type = sensor_msg/CameraInfo

+ rectifiedDistributor (/image_rect) - Redistributes the rectified image to the april tags detector
  type = sensor_msgs/Image

+ result_image (/darknet_ros/bounding_boxes) - Subscribes to YOLO ROS's description of where the objects are
  type = darknet_ros_msgs/BoundingBox (an array of classification types and (x,y) pairs associated with it)

+ apriltags (/tag_detections) - Subscribes to the april tag classification data stream
  type = apriltag_ros/AprilTagDetectionArray


PUBLISHERS:
+ calibrationMatrixLeftPub (/camera_rect/camera_info) - camera's calibration matrix
type = sensor_msgs/CameraInfo

+ redistributeCameraInfo (/camera_info) - actual image from Baxter's right wrist camera
type = sensor_msgs/Image

+ redistributeCameraInfo2 (/camera_rect/camera_info) - actual image from Baxter's right wrist camera
type = sensor_msgs/Image

+ pub (/image_raw) - raw camera feed
+ pub2 (/image_color) - color camera feed

+ publishRectified (/camera_rect/image_rect) - Redistributes the rectified image to the april tags detector

+ targetInfo (/targetBox) - Publishes the target's location

+ desiredGunPose (/gun_pose) - Publishes desired gun pose
"""

import math
import rospy
from cv_bridge import CvBridge
from sensor_msgs.msg import Image, CameraInfo, CompressedImage
import cv2
import actionlib
import tf
import numpy as np
from random import uniform
from darknet_ros_msgs.msg import BoundingBoxes
from apriltag_ros.msg import AprilTagDetectionArray
from geometry_msgs.msg import Pose, Point


# This class implements the image processing pipeline
# for our given task
class imageProcessor:


    # This node recieves from Baxter's camera
    # and publishes it in a format that YOLO ROS can use
    def process_initial_image(self, data):
        # pass
        # Publish the image we recieved so YOLO ROS can process it
        self.pub.publish(data)
        self.pub2.publish(data)

    # This function takes the classification data from YOLO ROS
    # and finds the (x,y) pair of the most probable desired object
    def process_final_image(self, data):

        maxProbability = -1
        mostProbableIndex = 0

        myList = data.bounding_boxes

        # Edge case: when there's not anythign in the image
        if ( myList is None):
            return

        if ( len(myList) <= 0):
            return

        # Used to record if the data stream really has a cup
        isThereCup = False

        # Search for the most probable human in the image
        # As of now, we will be shooting cups
        for i in range(len(myList) ):

            if (myList[i].Class == "cup" ):

                isThereCup = True

                if ( myList[i].probability  > maxProbability  ):
                    maxProbability = myList[i].probability
                    mostProbableIndex = i

        # If we have actually seen a cup, then print/publish the information
        if ( isThereCup == True ):
            # Average the bounds of the box
            x = (float(myList[mostProbableIndex].xmin + myList[mostProbableIndex].xmax) ) / 2.0
            y = (float(myList[mostProbableIndex].ymin + myList[mostProbableIndex].ymax) ) / 2.0

            # Republish the bounding box message
            x_average = float( (myList[mostProbableIndex].xmin + myList[mostProbableIndex].xmax ) ) / 2.0
            y_average = float( (myList[mostProbableIndex].ymin + myList[mostProbableIndex].ymax ) ) / 2.0

            print(x_average)


            p = Point()
            p.x = x_average
            p.y = y_average
            p.z = 0.0

            self.targetInfo.publish(p)

            # Print to the screen for testing
            rospy.loginfo("The deep net is most confident that a cup is at (" +
                str(x) + str(", ") + str(y) + str(")")  )


    # Callback for when receiving the apriltag data
    # strip off the data we don't need and publish just the pose
    # to the nodes which move the robot
    def apriltag_callback(self, data):


        myPose = Pose()

        # print( data.detections[2].pose.pose.pose )

        # if ( len(data.detections) > 1 ):
        # self.desiredGunPose.publish( data.detections[2].pose.pose.pose )

        # myPose.orientation = data.detections.pose
        # myPose.position =

        if ( len(data.detections) > 0):
            self.desiredGunPose.publish( data.detections[0].pose.pose.pose )
        else:
            pass

    # This method recieves the calibration matrix from Baxter's right arm
    # and publishes it to the correct topic so that apriltags can use it
    def publish_left_calibration(self, data):
        # Publish the info on the correct topic so apriltag_ros can use it
        self.calibrationMatrixLeftPub.publish(data)
        self.redistributeCameraInfo.publish(data)
        self.redistributeCameraInfo2.publish(data)


    def distributeRectified(self, data):
        self.publishRectified.publish(data)

    # Constructor method
    def __init__(self):
        self.leftCamera = rospy.Subscriber("/cameras/left_hand_camera/image", Image, self.process_initial_image)

        # self.leftCamera = rospy.Subscriber("/cameras/left_hand_camera/image", Image, self.process_image)
        # self.headCamera = rospy.Subscriber("/cameras/head_camera/image", Image, self.process_image)

        self.calibrationMatrixLeftSub = rospy.Subscriber("/cameras/left_hand_camera/camera_info_std", CameraInfo, self.publish_left_calibration)
        self.calibrationMatrixLeftPub =  rospy.Publisher("/camera/camera_info", CameraInfo, queue_size = 1)

        self.redistributeCameraInfo = rospy.Publisher("/camera_info", CameraInfo, queue_size = 1)
        self.redistributeCameraInfo2 = rospy.Publisher("/camera_rect/camera_info", CameraInfo, queue_size = 1)


        self.pub = rospy.Publisher("/image_raw", Image, queue_size = 1)
        self.pub2 = rospy.Publisher("/image_color", Image, queue_size = 1)

        # Redistributes the rectified image to the april tags detector
        self.rectifiedDistributor = rospy.Subscriber( "/image_rect", Image, self.distributeRectified )
        self.publishRectified = rospy.Publisher( "/camera_rect/image_rect", Image, queue_size = 1   )

        # /camera_rect/image_rect

        # Subscribe to YOLO ROS's description of where the objects are
        self.result_image = rospy.Subscriber("/darknet_ros/bounding_boxes", BoundingBoxes, self.process_final_image)

        # Create publisher to publish the target's location
        self.targetInfo =  rospy.Publisher("/targetBox", Point, queue_size = 1)

        # Subscribe to the april tag classification data stream
        self.apriltags = rospy.Subscriber("/tag_detections", AprilTagDetectionArray, self.apriltag_callback)
        self.desiredGunPose = rospy.Publisher("/gun_pose", Pose, queue_size = 1 )

# Main Function
if __name__ == "__main__":

    rospy.init_node("getCameraNode")

    # create object
    my_imageProcessor = imageProcessor()

    # Keep the thread alive by spinning
    rospy.spin()
